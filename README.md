# ğŸš€ Machine Learning II - Travaux Pratiques en Reinforcement Learning  

Ce repository contient les travaux pratiques rÃ©alisÃ©s dans le cadre du module **Machine Learning II**, axÃ© sur l'apprentissage par renforcement (*Reinforcement Learning*). L'objectif est d'explorer les concepts fondamentaux, d'expÃ©rimenter avec des algorithmes classiques et d'appliquer ces techniques Ã  des problÃ©matiques concrÃ¨tes.

## ğŸ“Œ Contenu du repository  

Ce projet est organisÃ© en quatre travaux pratiques (TP), chacun traitant un aspect clÃ© de l'apprentissage par renforcement :  

| TP  | Sujet  | Objectif  |
|------|--------|-----------|
| TP1  | Introduction Ã  OpenAI Gym  | Se familiariser avec les outils essentiels du Reinforcement Learning |
| TP2  | ImplÃ©mentation de Q-Learning | Mettre en pratique les concepts fondamentaux de l'apprentissage par renforcement |
| TP3  | Optimisation des feux de circulation | Appliquer l'apprentissage par renforcement Ã  un problÃ¨me du monde rÃ©el, et comparer Q-Learning avec SARSA|
| TP4  | Apprentissage profond pour les  jeux | Comprendre et expÃ©rimenter avec lâ€™algorithme **Proximal Policy Optimization (PPO)** |

## ğŸ›  Technologies utilisÃ©es  

- **Python 3.x**
- **Environnement de dÃ©veloppement** - RecommandÃ© : Jupyter / Colab / Vs Code
- **OpenAI Gym** â€“ Environnement de simulation pour le RL  
- **NumPy & Matplotlib** â€“ Manipulation des donnÃ©es et visualisation   

## ğŸ“š About OpenAI Gym
OpenAI Gym est une bibliothÃ¨que Python open-source dÃ©veloppÃ©e par OpenAI pour faciliter la crÃ©ation et lâ€™Ã©valuation des algorithmes dâ€™apprentissage par renforcement (RL).

### - Comment fonctionne?
OpenAI Gym repose sur une approche intuitive : il met Ã  disposition des environnements oÃ¹ un agent peut interagir en prenant des actions, recevant des rÃ©compenses ou des pÃ©nalitÃ©s, et observant les consÃ©quences de ses dÃ©cisions.

GrÃ¢ce Ã  une interface homogÃ¨ne pour tous les environnements, il simplifie le dÃ©veloppement et l'Ã©valuation d'algorithmes d'apprentissage par renforcement, en Ã©liminant le besoin de personnaliser le code pour des spÃ©cifications environnementales variÃ©es.

### - Les 4 principales caractÃ©ristiques dâ€™OpenAI Gym
OpenAI Gym offre plusieurs fonctionnalitÃ©s clÃ©s qui le rendent prÃ©cieux pour lâ€™apprentissage par renforcement :

<div align="center">
  <img src="https://www.allaboutai.com/wp-content/uploads/2024/09/Environment-Agent.gif" width="500">
</div>

- *Environnements* : Configurez et entraÃ®nez des agents dans une variÃ©tÃ© d'environnements Ã  l'aide de la fonction make, avec la possibilitÃ© de gÃ©rer des scÃ©narios multi-agents.

- *Wrappers* : Personnalisez les environnements existants en modifiant des paramÃ¨tres tels que les actions ou les rÃ©compenses, afin d'adapter le processus d'entraÃ®nement Ã  vos besoins spÃ©cifiques.

- *Actions* : DÃ©terminez la maniÃ¨re dont lâ€™agent rÃ©agit aux observations. Chaque action dÃ©clenche une Ã©tape dans lâ€™environnement, gÃ©nÃ©rant de nouvelles observations, des rÃ©compenses et des retours dâ€™Ã©tat.

- *Observations* : Collectez les donnÃ©es relatives Ã  lâ€™interaction de lâ€™agent avec lâ€™environnement, incluant des dÃ©tails pour faciliter le dÃ©bogage et suivre lâ€™Ã©volution des performances Ã©tape par Ã©tape.

### - Les avantages dâ€™OpenAI Gym
OpenAI Gym est essentiel pour toute personne travaillant avec lâ€™apprentissage par renforcement, offrant une maniÃ¨re contrÃ´lÃ©e et flexible de dÃ©velopper et tester des modÃ¨les dâ€™IA. Voici pourquoi il est indispensable :

<div align="center">
  <img src="https://www.allaboutai.com/wp-content/uploads/2025/01/Interaction-Protocols-in-Object-Interaction-768x576.png.webp" width="500">
</div>

## ğŸš€ Instructions d'installation  

1. **Cloner le repository**  
   ```bash
   git clone https://github.com/soukayna-thr/ML2-Reinforcement-Learning.git
   
2. **AccÃ©der au projet**  
   ```bash
   cd ML2-Reinforcement-Learning

## ğŸ“Š RÃ©sultats et observations
Les rÃ©sultats dÃ©taillÃ©s de chaque TP (apprentissage des agents, graphiques, scores obtenus) sont disponibles dans les notebooks et les fichiers de rapport correspondants.

ğŸ“œ Licence
---
Ce projet est distribuÃ© sous la licence MIT. Consultez le fichier [LICENSE](LICENSE) pour plus d'informations.
