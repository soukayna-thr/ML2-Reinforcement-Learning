# Machine Learning II - Travaux Pratiques en Reinforcement Learning  

Ce repository contient les travaux pratiques r√©alis√©s dans le cadre du module **Machine Learning II**, ax√© sur l'apprentissage par renforcement (*Reinforcement Learning*). L'objectif est d'explorer les concepts fondamentaux, d'exp√©rimenter avec des algorithmes classiques et d'appliquer ces techniques √† des probl√©matiques concr√®tes.

## I. Contenu du repository  

Ce projet est organis√© en quatre travaux pratiques (TP), chacun traitant un aspect cl√© de l'apprentissage par renforcement :  

| TP  | Sujet  | Objectif  |
|------|--------|-----------|
| TP1  | Introduction √† OpenAI Gym  | Se familiariser avec les outils essentiels du Reinforcement Learning |
| TP2  | Impl√©mentation de Q-Learning | Mettre en pratique les concepts fondamentaux de l'apprentissage par renforcement |
| TP3  | Optimisation des feux de circulation | Appliquer l'apprentissage par renforcement √† un probl√®me du monde r√©el, et comparer Q-Learning avec SARSA|
| TP4  | Apprentissage profond pour les  jeux | Comprendre et exp√©rimenter avec l‚Äôalgorithme **Proximal Policy Optimization (PPO)** |
| TP5  | Apprentissage par renforcement avec TF-Agents | D√©covrir l'utilisation pratique de la biblioth√©que TensorFlow Agents (TF-Agents)  | 

## II. Technologies utilis√©es  

- **Python 3.x**
- **Environnement de d√©veloppement** - Recommand√© : Jupyter / Colab / Vs Code
- **OpenAI Gym** ‚Äì Environnement de simulation pour le RL  
- **NumPy & Matplotlib** ‚Äì Manipulation des donn√©es et visualisation   

## III. Instructions d'installation  

1. **Cloner le repository**  
   ```bash
   git clone https://github.com/soukayna-thr/ML2-Reinforcement-Learning.git
   
2. **Acc√©der au projet**  
   ```bash
   cd ML2-Reinforcement-Learning

## IV. R√©sultats et observations
Les r√©sultats d√©taill√©s de chaque TP (apprentissage des agents, graphiques, scores obtenus) sont disponibles dans les notebooks et les fichiers correspondants.

üìú Licence
---
Ce projet est distribu√© sous la licence MIT. Consultez le fichier [LICENSE](LICENSE) pour plus d'informations.
