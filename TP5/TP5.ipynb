{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Machine Learning II - TP5 : Apprentissage par renforcement avec TF-Agents**"
      ],
      "metadata": {
        "id": "fs2VV7nvGv_S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Installation des bibliothÃ©ques**"
      ],
      "metadata": {
        "id": "xfYGLcW7G6BR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "QmS6Swob5Ac4",
        "outputId": "60fec928-384e-435e-a3ab-110accc237bc"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.15.0\n",
            "  Using cached tensorflow-2.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Collecting absl-py>=1.0.0 (from tensorflow==2.15.0)\n",
            "  Using cached absl_py-2.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting astunparse>=1.6.0 (from tensorflow==2.15.0)\n",
            "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting flatbuffers>=23.5.26 (from tensorflow==2.15.0)\n",
            "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
            "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow==2.15.0)\n",
            "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting google-pasta>=0.1.1 (from tensorflow==2.15.0)\n",
            "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
            "Collecting h5py>=2.9.0 (from tensorflow==2.15.0)\n",
            "  Using cached h5py-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
            "Collecting libclang>=13.0.0 (from tensorflow==2.15.0)\n",
            "  Using cached libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
            "Collecting ml-dtypes~=0.2.0 (from tensorflow==2.15.0)\n",
            "  Using cached ml_dtypes-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting numpy<2.0.0,>=1.23.5 (from tensorflow==2.15.0)\n",
            "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting opt-einsum>=2.3.2 (from tensorflow==2.15.0)\n",
            "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting packaging (from tensorflow==2.15.0)\n",
            "  Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow==2.15.0)\n",
            "  Using cached protobuf-4.25.6-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Collecting setuptools (from tensorflow==2.15.0)\n",
            "  Using cached setuptools-78.1.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting six>=1.12.0 (from tensorflow==2.15.0)\n",
            "  Using cached six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting termcolor>=1.1.0 (from tensorflow==2.15.0)\n",
            "  Using cached termcolor-3.0.1-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting typing-extensions>=3.6.6 (from tensorflow==2.15.0)\n",
            "  Using cached typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow==2.15.0)\n",
            "  Using cached wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow==2.15.0)\n",
            "  Using cached tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Collecting grpcio<2.0,>=1.24.3 (from tensorflow==2.15.0)\n",
            "  Using cached grpcio-1.71.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting tensorboard<2.16,>=2.15 (from tensorflow==2.15.0)\n",
            "  Using cached tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow==2.15.0)\n",
            "  Using cached tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting keras<2.16,>=2.15.0 (from tensorflow==2.15.0)\n",
            "  Using cached keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow==2.15.0)\n",
            "  Using cached wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting google-auth<3,>=1.6.3 (from tensorboard<2.16,>=2.15->tensorflow==2.15.0)\n",
            "  Using cached google_auth-2.39.0-py2.py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting google-auth-oauthlib<2,>=0.5 (from tensorboard<2.16,>=2.15->tensorflow==2.15.0)\n",
            "  Using cached google_auth_oauthlib-1.2.1-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting markdown>=2.6.8 (from tensorboard<2.16,>=2.15->tensorflow==2.15.0)\n",
            "  Using cached markdown-3.8-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting requests<3,>=2.21.0 (from tensorboard<2.16,>=2.15->tensorflow==2.15.0)\n",
            "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.16,>=2.15->tensorflow==2.15.0)\n",
            "  Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting werkzeug>=1.0.1 (from tensorboard<2.16,>=2.15->tensorflow==2.15.0)\n",
            "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0)\n",
            "  Using cached cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0)\n",
            "  Using cached pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0)\n",
            "  Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0)\n",
            "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Collecting charset-normalizer<4,>=2 (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0)\n",
            "  Using cached charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
            "Collecting idna<4,>=2.5 (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0)\n",
            "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0)\n",
            "  Using cached urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0)\n",
            "  Using cached certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15.0)\n",
            "  Using cached MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting pyasn1<0.7.0,>=0.6.1 (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0)\n",
            "  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0)\n",
            "  Using cached oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
            "Using cached tensorflow-2.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.3 MB)\n",
            "Using cached absl_py-2.2.2-py3-none-any.whl (135 kB)\n",
            "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Using cached flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
            "Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
            "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "Using cached grpcio-1.71.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "Using cached h5py-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "Using cached keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
            "Using cached libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
            "Using cached ml_dtypes-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
            "Using cached protobuf-4.25.6-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "Using cached six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Using cached tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n",
            "Using cached setuptools-78.1.0-py3-none-any.whl (1.3 MB)\n",
            "Using cached tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
            "Using cached tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "Using cached termcolor-3.0.1-py3-none-any.whl (7.2 kB)\n",
            "Using cached typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
            "Using cached wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB)\n",
            "Using cached packaging-24.2-py3-none-any.whl (65 kB)\n",
            "Using cached google_auth-2.39.0-py2.py3-none-any.whl (212 kB)\n",
            "Using cached google_auth_oauthlib-1.2.1-py2.py3-none-any.whl (24 kB)\n",
            "Using cached markdown-3.8-py3-none-any.whl (106 kB)\n",
            "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
            "Using cached wheel-0.45.1-py3-none-any.whl (72 kB)\n",
            "Using cached cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
            "Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
            "Using cached charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (143 kB)\n",
            "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
            "Using cached MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
            "Using cached pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
            "Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
            "Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
            "Using cached urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
            "Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
            "Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
            "Installing collected packages: libclang, flatbuffers, wrapt, wheel, urllib3, typing-extensions, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, six, setuptools, pyasn1, protobuf, packaging, opt-einsum, oauthlib, numpy, MarkupSafe, markdown, keras, idna, grpcio, gast, charset-normalizer, certifi, cachetools, absl-py, werkzeug, rsa, requests, pyasn1-modules, ml-dtypes, h5py, google-pasta, astunparse, requests-oauthlib, google-auth, google-auth-oauthlib, tensorboard, tensorflow\n",
            "  Attempting uninstall: libclang\n",
            "    Found existing installation: libclang 18.1.1\n",
            "    Uninstalling libclang-18.1.1:\n",
            "      Successfully uninstalled libclang-18.1.1\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 25.2.10\n",
            "    Uninstalling flatbuffers-25.2.10:\n",
            "      Successfully uninstalled flatbuffers-25.2.10\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.14.1\n",
            "    Uninstalling wrapt-1.14.1:\n",
            "      Successfully uninstalled wrapt-1.14.1\n",
            "  Attempting uninstall: wheel\n",
            "    Found existing installation: wheel 0.45.1\n",
            "    Uninstalling wheel-0.45.1:\n",
            "      Successfully uninstalled wheel-0.45.1\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.4.0\n",
            "    Uninstalling urllib3-2.4.0:\n",
            "      Successfully uninstalled urllib3-2.4.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "  Attempting uninstall: termcolor\n",
            "    Found existing installation: termcolor 3.0.1\n",
            "    Uninstalling termcolor-3.0.1:\n",
            "      Successfully uninstalled termcolor-3.0.1\n",
            "  Attempting uninstall: tensorflow-io-gcs-filesystem\n",
            "    Found existing installation: tensorflow-io-gcs-filesystem 0.37.1\n",
            "    Uninstalling tensorflow-io-gcs-filesystem-0.37.1:\n",
            "      Successfully uninstalled tensorflow-io-gcs-filesystem-0.37.1\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.12.0\n",
            "    Uninstalling tensorflow-estimator-2.12.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.12.0\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.2\n",
            "    Uninstalling tensorboard-data-server-0.7.2:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.2\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.17.0\n",
            "    Uninstalling six-1.17.0:\n",
            "      Successfully uninstalled six-1.17.0\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 78.1.0\n",
            "    Uninstalling setuptools-78.1.0:\n",
            "      Successfully uninstalled setuptools-78.1.0\n",
            "  Attempting uninstall: pyasn1\n",
            "    Found existing installation: pyasn1 0.6.1\n",
            "    Uninstalling pyasn1-0.6.1:\n",
            "      Successfully uninstalled pyasn1-0.6.1\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.6\n",
            "    Uninstalling protobuf-4.25.6:\n",
            "      Successfully uninstalled protobuf-4.25.6\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.2\n",
            "    Uninstalling packaging-24.2:\n",
            "      Successfully uninstalled packaging-24.2\n",
            "  Attempting uninstall: opt-einsum\n",
            "    Found existing installation: opt_einsum 3.4.0\n",
            "    Uninstalling opt_einsum-3.4.0:\n",
            "      Successfully uninstalled opt_einsum-3.4.0\n",
            "  Attempting uninstall: oauthlib\n",
            "    Found existing installation: oauthlib 3.2.2\n",
            "    Uninstalling oauthlib-3.2.2:\n",
            "      Successfully uninstalled oauthlib-3.2.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.23.5\n",
            "    Uninstalling numpy-1.23.5:\n",
            "      Successfully uninstalled numpy-1.23.5\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: markdown\n",
            "    Found existing installation: Markdown 3.8\n",
            "    Uninstalling Markdown-3.8:\n",
            "      Successfully uninstalled Markdown-3.8\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.12.0\n",
            "    Uninstalling keras-2.12.0:\n",
            "      Successfully uninstalled keras-2.12.0\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.71.0\n",
            "    Uninstalling grpcio-1.71.0:\n",
            "      Successfully uninstalled grpcio-1.71.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 3.4.1\n",
            "    Uninstalling charset-normalizer-3.4.1:\n",
            "      Successfully uninstalled charset-normalizer-3.4.1\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2025.1.31\n",
            "    Uninstalling certifi-2025.1.31:\n",
            "      Successfully uninstalled certifi-2025.1.31\n",
            "  Attempting uninstall: cachetools\n",
            "    Found existing installation: cachetools 5.5.2\n",
            "    Uninstalling cachetools-5.5.2:\n",
            "      Successfully uninstalled cachetools-5.5.2\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 2.2.2\n",
            "    Uninstalling absl-py-2.2.2:\n",
            "      Successfully uninstalled absl-py-2.2.2\n",
            "  Attempting uninstall: werkzeug\n",
            "    Found existing installation: Werkzeug 3.1.3\n",
            "    Uninstalling Werkzeug-3.1.3:\n",
            "      Successfully uninstalled Werkzeug-3.1.3\n",
            "  Attempting uninstall: rsa\n",
            "    Found existing installation: rsa 4.9\n",
            "    Uninstalling rsa-4.9:\n",
            "      Successfully uninstalled rsa-4.9\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "  Attempting uninstall: pyasn1-modules\n",
            "    Found existing installation: pyasn1_modules 0.4.2\n",
            "    Uninstalling pyasn1_modules-0.4.2:\n",
            "      Successfully uninstalled pyasn1_modules-0.4.2\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml_dtypes 0.5.1\n",
            "    Uninstalling ml_dtypes-0.5.1:\n",
            "      Successfully uninstalled ml_dtypes-0.5.1\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.13.0\n",
            "    Uninstalling h5py-3.13.0:\n",
            "      Successfully uninstalled h5py-3.13.0\n",
            "  Attempting uninstall: google-pasta\n",
            "    Found existing installation: google-pasta 0.2.0\n",
            "    Uninstalling google-pasta-0.2.0:\n",
            "      Successfully uninstalled google-pasta-0.2.0\n",
            "  Attempting uninstall: astunparse\n",
            "    Found existing installation: astunparse 1.6.3\n",
            "    Uninstalling astunparse-1.6.3:\n",
            "      Successfully uninstalled astunparse-1.6.3\n",
            "  Attempting uninstall: requests-oauthlib\n",
            "    Found existing installation: requests-oauthlib 2.0.0\n",
            "    Uninstalling requests-oauthlib-2.0.0:\n",
            "      Successfully uninstalled requests-oauthlib-2.0.0\n",
            "  Attempting uninstall: google-auth\n",
            "    Found existing installation: google-auth 2.39.0\n",
            "    Uninstalling google-auth-2.39.0:\n",
            "      Successfully uninstalled google-auth-2.39.0\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.0.0\n",
            "    Uninstalling google-auth-oauthlib-1.0.0:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.0.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.12.3\n",
            "    Uninstalling tensorboard-2.12.3:\n",
            "      Successfully uninstalled tensorboard-2.12.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.12.1\n",
            "    Uninstalling tensorflow-2.12.1:\n",
            "      Successfully uninstalled tensorflow-2.12.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "jax 0.4.38 requires ml_dtypes>=0.4.0, but you have ml-dtypes 0.2.0 which is incompatible.\n",
            "google-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.39.0 which is incompatible.\n",
            "google-colab 1.0.0 requires portpicker==1.5.2, but you have portpicker 1.6.0 which is incompatible.\n",
            "moviepy 1.0.3 requires decorator<5.0,>=4.0.2, but you have decorator 5.2.1 which is incompatible.\n",
            "tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.15.0 which is incompatible.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.15.0 which is incompatible.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.15.0 which is incompatible.\n",
            "flax 0.10.5 requires jax>=0.5.1, but you have jax 0.4.38 which is incompatible.\n",
            "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.6 which is incompatible.\n",
            "tensorstore 0.1.73 requires ml_dtypes>=0.3.1, but you have ml-dtypes 0.2.0 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.6 which is incompatible.\n",
            "orbax-checkpoint 0.11.12 requires jax>=0.5.0, but you have jax 0.4.38 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-3.0.2 absl-py-2.2.2 astunparse-1.6.3 cachetools-5.5.2 certifi-2025.1.31 charset-normalizer-3.4.1 flatbuffers-25.2.10 gast-0.6.0 google-auth-2.39.0 google-auth-oauthlib-1.2.1 google-pasta-0.2.0 grpcio-1.71.0 h5py-3.13.0 idna-3.10 keras-2.15.0 libclang-18.1.1 markdown-3.8 ml-dtypes-0.2.0 numpy-1.26.4 oauthlib-3.2.2 opt-einsum-3.4.0 packaging-24.2 protobuf-4.25.6 pyasn1-0.6.1 pyasn1-modules-0.4.2 requests-2.32.3 requests-oauthlib-2.0.0 rsa-4.9 setuptools-78.1.0 six-1.17.0 tensorboard-2.15.2 tensorboard-data-server-0.7.2 tensorflow-2.15.0 tensorflow-estimator-2.15.0 tensorflow-io-gcs-filesystem-0.37.1 termcolor-3.0.1 typing-extensions-4.13.2 urllib3-2.4.0 werkzeug-3.1.3 wheel-0.45.1 wrapt-1.14.1\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "792be00bdacd4a60a9ebcb35d79b705e",
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "absl",
                  "astunparse",
                  "cachetools",
                  "certifi",
                  "charset_normalizer",
                  "flatbuffers",
                  "gast",
                  "google",
                  "h5py",
                  "keras",
                  "ml_dtypes",
                  "pkg_resources",
                  "pyasn1",
                  "pyasn1_modules",
                  "requests",
                  "setuptools",
                  "six",
                  "tensorboard",
                  "tensorflow",
                  "wrapt"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tf-agents==0.16.0 (from tf-agents[reverb]==0.16.0)\n",
            "  Using cached tf_agents-0.16.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting absl-py>=0.6.1 (from tf-agents==0.16.0->tf-agents[reverb]==0.16.0)\n",
            "  Using cached absl_py-2.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting cloudpickle>=1.3 (from tf-agents==0.16.0->tf-agents[reverb]==0.16.0)\n",
            "  Using cached cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting gin-config>=0.4.0 (from tf-agents==0.16.0->tf-agents[reverb]==0.16.0)\n",
            "  Using cached gin_config-0.5.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting gym<=0.23.0,>=0.17.0 (from tf-agents==0.16.0->tf-agents[reverb]==0.16.0)\n",
            "  Using cached gym-0.23.0-py3-none-any.whl\n",
            "Collecting numpy>=1.19.0 (from tf-agents==0.16.0->tf-agents[reverb]==0.16.0)\n",
            "  Using cached numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Collecting pillow (from tf-agents==0.16.0->tf-agents[reverb]==0.16.0)\n",
            "  Using cached pillow-11.2.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
            "Collecting six>=1.10.0 (from tf-agents==0.16.0->tf-agents[reverb]==0.16.0)\n",
            "  Using cached six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting protobuf>=3.11.3 (from tf-agents==0.16.0->tf-agents[reverb]==0.16.0)\n",
            "  Using cached protobuf-6.30.2-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
            "Collecting wrapt>=1.11.1 (from tf-agents==0.16.0->tf-agents[reverb]==0.16.0)\n",
            "  Using cached wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
            "Collecting typing-extensions>=3.7.4.3 (from tf-agents==0.16.0->tf-agents[reverb]==0.16.0)\n",
            "  Using cached typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting pygame==2.1.3 (from tf-agents==0.16.0->tf-agents[reverb]==0.16.0)\n",
            "  Using cached pygame-2.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\n",
            "Collecting tensorflow-probability~=0.19.0 (from tf-agents==0.16.0->tf-agents[reverb]==0.16.0)\n",
            "  Using cached tensorflow_probability-0.19.0-py2.py3-none-any.whl.metadata (13 kB)\n",
            "Collecting rlds (from tf-agents[reverb]==0.16.0)\n",
            "  Using cached rlds-0.1.8-py3-none-manylinux2010_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting dm-reverb~=0.11.0 (from tf-agents[reverb]==0.16.0)\n",
            "  Using cached dm_reverb-0.11.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Collecting tensorflow~=2.12.0 (from tf-agents[reverb]==0.16.0)\n",
            "  Using cached tensorflow-2.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting dm-tree (from dm-reverb~=0.11.0->tf-agents[reverb]==0.16.0)\n",
            "  Using cached dm_tree-0.1.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\n",
            "Collecting portpicker (from dm-reverb~=0.11.0->tf-agents[reverb]==0.16.0)\n",
            "  Using cached portpicker-1.6.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting gym_notices>=0.0.4 (from gym<=0.23.0,>=0.17.0->tf-agents==0.16.0->tf-agents[reverb]==0.16.0)\n",
            "  Using cached gym_notices-0.0.8-py3-none-any.whl.metadata (1.0 kB)\n",
            "Collecting astunparse>=1.6.0 (from tensorflow~=2.12.0->tf-agents[reverb]==0.16.0)\n",
            "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting flatbuffers>=2.0 (from tensorflow~=2.12.0->tf-agents[reverb]==0.16.0)\n",
            "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
            "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow~=2.12.0->tf-agents[reverb]==0.16.0)\n",
            "  Using cached gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting google-pasta>=0.1.1 (from tensorflow~=2.12.0->tf-agents[reverb]==0.16.0)\n",
            "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
            "Collecting grpcio<2.0,>=1.24.3 (from tensorflow~=2.12.0->tf-agents[reverb]==0.16.0)\n",
            "  Using cached grpcio-1.71.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting h5py>=2.9.0 (from tensorflow~=2.12.0->tf-agents[reverb]==0.16.0)\n",
            "  Using cached h5py-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow~=2.12.0->tf-agents[reverb]==0.16.0)\n",
            "  Using cached jax-0.5.3-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting keras<2.13,>=2.12.0 (from tensorflow~=2.12.0->tf-agents[reverb]==0.16.0)\n",
            "  Using cached keras-2.12.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting libclang>=13.0.0 (from tensorflow~=2.12.0->tf-agents[reverb]==0.16.0)\n",
            "  Using cached libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
            "Collecting numpy>=1.19.0 (from tf-agents==0.16.0->tf-agents[reverb]==0.16.0)\n",
            "  Using cached numpy-1.24.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Collecting opt-einsum>=2.3.2 (from tensorflow~=2.12.0->tf-agents[reverb]==0.16.0)\n",
            "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting packaging (from tensorflow~=2.12.0->tf-agents[reverb]==0.16.0)\n",
            "  Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting protobuf>=3.11.3 (from tf-agents==0.16.0->tf-agents[reverb]==0.16.0)\n",
            "  Using cached protobuf-4.25.6-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Collecting setuptools (from tensorflow~=2.12.0->tf-agents[reverb]==0.16.0)\n",
            "  Using cached setuptools-78.1.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting tensorboard<2.13,>=2.12 (from tensorflow~=2.12.0->tf-agents[reverb]==0.16.0)\n",
            "  Using cached tensorboard-2.12.3-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting tensorflow-estimator<2.13,>=2.12.0 (from tensorflow~=2.12.0->tf-agents[reverb]==0.16.0)\n",
            "  Using cached tensorflow_estimator-2.12.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting termcolor>=1.1.0 (from tensorflow~=2.12.0->tf-agents[reverb]==0.16.0)\n",
            "  Using cached termcolor-3.0.1-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting typing-extensions>=3.7.4.3 (from tf-agents==0.16.0->tf-agents[reverb]==0.16.0)\n",
            "  Using cached typing_extensions-4.5.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting wrapt>=1.11.1 (from tf-agents==0.16.0->tf-agents[reverb]==0.16.0)\n",
            "  Using cached wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow~=2.12.0->tf-agents[reverb]==0.16.0)\n",
            "  Using cached tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Collecting decorator (from tensorflow-probability~=0.19.0->tf-agents==0.16.0->tf-agents[reverb]==0.16.0)\n",
            "  Using cached decorator-5.2.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow~=2.12.0->tf-agents[reverb]==0.16.0)\n",
            "  Using cached wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting jaxlib<=0.5.3,>=0.5.3 (from jax>=0.3.15->tensorflow~=2.12.0->tf-agents[reverb]==0.16.0)\n",
            "  Using cached jaxlib-0.5.3-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting ml_dtypes>=0.4.0 (from jax>=0.3.15->tensorflow~=2.12.0->tf-agents[reverb]==0.16.0)\n",
            "  Using cached ml_dtypes-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "INFO: pip is looking at multiple versions of jax to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting jax>=0.3.15 (from tensorflow~=2.12.0->tf-agents[reverb]==0.16.0)\n",
            "  Using cached jax-0.5.2-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.5.2,>=0.5.1 (from jax>=0.3.15->tensorflow~=2.12.0->tf-agents[reverb]==0.16.0)\n",
            "  Using cached jaxlib-0.5.1-cp311-cp311-manylinux2014_x86_64.whl.metadata (978 bytes)\n",
            "Collecting jax>=0.3.15 (from tensorflow~=2.12.0->tf-agents[reverb]==0.16.0)\n",
            "  Using cached jax-0.5.1-py3-none-any.whl.metadata (22 kB)\n",
            "  Using cached jax-0.5.0-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.5.0,>=0.5.0 (from jax>=0.3.15->tensorflow~=2.12.0->tf-agents[reverb]==0.16.0)\n",
            "  Using cached jaxlib-0.5.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (978 bytes)\n",
            "Collecting jax>=0.3.15 (from tensorflow~=2.12.0->tf-agents[reverb]==0.16.0)\n",
            "  Using cached jax-0.4.38-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.38,>=0.4.38 (from jax>=0.3.15->tensorflow~=2.12.0->tf-agents[reverb]==0.16.0)\n",
            "  Using cached jaxlib-0.4.38-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting scipy>=1.10 (from jax>=0.3.15->tensorflow~=2.12.0->tf-agents[reverb]==0.16.0)\n",
            "  Using cached scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting google-auth<3,>=1.6.3 (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]==0.16.0)\n",
            "  Using cached google_auth-2.39.0-py2.py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]==0.16.0)\n",
            "  Using cached google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting markdown>=2.6.8 (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]==0.16.0)\n",
            "  Using cached markdown-3.8-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting requests<3,>=2.21.0 (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]==0.16.0)\n",
            "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]==0.16.0)\n",
            "  Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting werkzeug>=1.0.1 (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]==0.16.0)\n",
            "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting attrs>=18.2.0 (from dm-tree->dm-reverb~=0.11.0->tf-agents[reverb]==0.16.0)\n",
            "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting psutil (from portpicker->dm-reverb~=0.11.0->tf-agents[reverb]==0.16.0)\n",
            "  Using cached psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]==0.16.0)\n",
            "  Using cached cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]==0.16.0)\n",
            "  Using cached pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]==0.16.0)\n",
            "  Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]==0.16.0)\n",
            "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Collecting charset-normalizer<4,>=2 (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]==0.16.0)\n",
            "  Using cached charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
            "Collecting idna<4,>=2.5 (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]==0.16.0)\n",
            "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]==0.16.0)\n",
            "  Using cached urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]==0.16.0)\n",
            "  Using cached certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]==0.16.0)\n",
            "  Using cached MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting pyasn1<0.7.0,>=0.6.1 (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]==0.16.0)\n",
            "  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]==0.16.0)\n",
            "  Using cached oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
            "Using cached tf_agents-0.16.0-py3-none-any.whl (1.4 MB)\n",
            "Using cached pygame-2.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.7 MB)\n",
            "Using cached absl_py-2.2.2-py3-none-any.whl (135 kB)\n",
            "Using cached cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
            "Using cached dm_reverb-0.11.0-cp311-cp311-manylinux2014_x86_64.whl (6.3 MB)\n",
            "Using cached gin_config-0.5.0-py3-none-any.whl (61 kB)\n",
            "Using cached six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Using cached tensorflow-2.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (585.9 MB)\n",
            "Using cached numpy-1.24.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "Using cached protobuf-4.25.6-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "Using cached tensorflow_probability-0.19.0-py2.py3-none-any.whl (6.7 MB)\n",
            "Using cached typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
            "Using cached wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB)\n",
            "Using cached pillow-11.2.1-cp311-cp311-manylinux_2_28_x86_64.whl (4.6 MB)\n",
            "Using cached rlds-0.1.8-py3-none-manylinux2010_x86_64.whl (48 kB)\n",
            "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Using cached flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
            "Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "Using cached grpcio-1.71.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "Using cached gym_notices-0.0.8-py3-none-any.whl (3.0 kB)\n",
            "Using cached h5py-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "Using cached jax-0.4.38-py3-none-any.whl (2.2 MB)\n",
            "Using cached keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
            "Using cached libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
            "Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
            "Using cached tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n",
            "Using cached setuptools-78.1.0-py3-none-any.whl (1.3 MB)\n",
            "Using cached tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
            "Using cached tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "Using cached termcolor-3.0.1-py3-none-any.whl (7.2 kB)\n",
            "Using cached decorator-5.2.1-py3-none-any.whl (9.2 kB)\n",
            "Using cached dm_tree-0.1.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (152 kB)\n",
            "Using cached packaging-24.2-py3-none-any.whl (65 kB)\n",
            "Using cached portpicker-1.6.0-py3-none-any.whl (16 kB)\n",
            "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
            "Using cached google_auth-2.39.0-py2.py3-none-any.whl (212 kB)\n",
            "Using cached google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Using cached jaxlib-0.4.38-cp311-cp311-manylinux2014_x86_64.whl (101.8 MB)\n",
            "Using cached markdown-3.8-py3-none-any.whl (106 kB)\n",
            "Using cached ml_dtypes-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "Using cached scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.6 MB)\n",
            "Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
            "Using cached wheel-0.45.1-py3-none-any.whl (72 kB)\n",
            "Using cached psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (277 kB)\n",
            "Using cached cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
            "Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
            "Using cached charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (143 kB)\n",
            "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
            "Using cached MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
            "Using cached pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
            "Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
            "Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
            "Using cached urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
            "Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
            "Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
            "Installing collected packages: libclang, gym_notices, gin-config, flatbuffers, wrapt, wheel, urllib3, typing-extensions, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, six, setuptools, pygame, pyasn1, psutil, protobuf, pillow, packaging, opt-einsum, oauthlib, numpy, MarkupSafe, markdown, keras, idna, grpcio, gast, decorator, cloudpickle, charset-normalizer, certifi, cachetools, attrs, absl-py, werkzeug, scipy, rsa, rlds, requests, pyasn1-modules, portpicker, ml_dtypes, h5py, gym, google-pasta, dm-tree, astunparse, tensorflow-probability, requests-oauthlib, jaxlib, google-auth, dm-reverb, tf-agents, jax, google-auth-oauthlib, tensorboard, tensorflow\n",
            "  Attempting uninstall: libclang\n",
            "    Found existing installation: libclang 18.1.1\n",
            "    Uninstalling libclang-18.1.1:\n",
            "      Successfully uninstalled libclang-18.1.1\n",
            "  Attempting uninstall: gym_notices\n",
            "    Found existing installation: gym-notices 0.0.8\n",
            "    Uninstalling gym-notices-0.0.8:\n",
            "      Successfully uninstalled gym-notices-0.0.8\n",
            "  Attempting uninstall: gin-config\n",
            "    Found existing installation: gin-config 0.5.0\n",
            "    Uninstalling gin-config-0.5.0:\n",
            "      Successfully uninstalled gin-config-0.5.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 25.2.10\n",
            "    Uninstalling flatbuffers-25.2.10:\n",
            "      Successfully uninstalled flatbuffers-25.2.10\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.14.1\n",
            "    Uninstalling wrapt-1.14.1:\n",
            "      Successfully uninstalled wrapt-1.14.1\n",
            "  Attempting uninstall: wheel\n",
            "    Found existing installation: wheel 0.45.1\n",
            "    Uninstalling wheel-0.45.1:\n",
            "      Successfully uninstalled wheel-0.45.1\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.4.0\n",
            "    Uninstalling urllib3-2.4.0:\n",
            "      Successfully uninstalled urllib3-2.4.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.13.2\n",
            "    Uninstalling typing_extensions-4.13.2:\n",
            "      Successfully uninstalled typing_extensions-4.13.2\n",
            "  Attempting uninstall: termcolor\n",
            "    Found existing installation: termcolor 3.0.1\n",
            "    Uninstalling termcolor-3.0.1:\n",
            "      Successfully uninstalled termcolor-3.0.1\n",
            "  Attempting uninstall: tensorflow-io-gcs-filesystem\n",
            "    Found existing installation: tensorflow-io-gcs-filesystem 0.37.1\n",
            "    Uninstalling tensorflow-io-gcs-filesystem-0.37.1:\n",
            "      Successfully uninstalled tensorflow-io-gcs-filesystem-0.37.1\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.15.0\n",
            "    Uninstalling tensorflow-estimator-2.15.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.15.0\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.2\n",
            "    Uninstalling tensorboard-data-server-0.7.2:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.2\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.17.0\n",
            "    Uninstalling six-1.17.0:\n",
            "      Successfully uninstalled six-1.17.0\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 78.1.0\n",
            "    Uninstalling setuptools-78.1.0:\n",
            "      Successfully uninstalled setuptools-78.1.0\n",
            "  Attempting uninstall: pygame\n",
            "    Found existing installation: pygame 2.1.3\n",
            "    Uninstalling pygame-2.1.3:\n",
            "      Successfully uninstalled pygame-2.1.3\n",
            "  Attempting uninstall: pyasn1\n",
            "    Found existing installation: pyasn1 0.6.1\n",
            "    Uninstalling pyasn1-0.6.1:\n",
            "      Successfully uninstalled pyasn1-0.6.1\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 7.0.0\n",
            "    Uninstalling psutil-7.0.0:\n",
            "      Successfully uninstalled psutil-7.0.0\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.6\n",
            "    Uninstalling protobuf-4.25.6:\n",
            "      Successfully uninstalled protobuf-4.25.6\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.2.1\n",
            "    Uninstalling pillow-11.2.1:\n",
            "      Successfully uninstalled pillow-11.2.1\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.2\n",
            "    Uninstalling packaging-24.2:\n",
            "      Successfully uninstalled packaging-24.2\n",
            "  Attempting uninstall: opt-einsum\n",
            "    Found existing installation: opt_einsum 3.4.0\n",
            "    Uninstalling opt_einsum-3.4.0:\n",
            "      Successfully uninstalled opt_einsum-3.4.0\n",
            "  Attempting uninstall: oauthlib\n",
            "    Found existing installation: oauthlib 3.2.2\n",
            "    Uninstalling oauthlib-3.2.2:\n",
            "      Successfully uninstalled oauthlib-3.2.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: markdown\n",
            "    Found existing installation: Markdown 3.8\n",
            "    Uninstalling Markdown-3.8:\n",
            "      Successfully uninstalled Markdown-3.8\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.71.0\n",
            "    Uninstalling grpcio-1.71.0:\n",
            "      Successfully uninstalled grpcio-1.71.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.6.0\n",
            "    Uninstalling gast-0.6.0:\n",
            "      Successfully uninstalled gast-0.6.0\n",
            "  Attempting uninstall: decorator\n",
            "    Found existing installation: decorator 5.2.1\n",
            "    Uninstalling decorator-5.2.1:\n",
            "      Successfully uninstalled decorator-5.2.1\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 3.1.1\n",
            "    Uninstalling cloudpickle-3.1.1:\n",
            "      Successfully uninstalled cloudpickle-3.1.1\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 3.4.1\n",
            "    Uninstalling charset-normalizer-3.4.1:\n",
            "      Successfully uninstalled charset-normalizer-3.4.1\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2025.1.31\n",
            "    Uninstalling certifi-2025.1.31:\n",
            "      Successfully uninstalled certifi-2025.1.31\n",
            "  Attempting uninstall: cachetools\n",
            "    Found existing installation: cachetools 5.5.2\n",
            "    Uninstalling cachetools-5.5.2:\n",
            "      Successfully uninstalled cachetools-5.5.2\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 25.3.0\n",
            "    Uninstalling attrs-25.3.0:\n",
            "      Successfully uninstalled attrs-25.3.0\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 2.2.2\n",
            "    Uninstalling absl-py-2.2.2:\n",
            "      Successfully uninstalled absl-py-2.2.2\n",
            "  Attempting uninstall: werkzeug\n",
            "    Found existing installation: Werkzeug 3.1.3\n",
            "    Uninstalling Werkzeug-3.1.3:\n",
            "      Successfully uninstalled Werkzeug-3.1.3\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.15.2\n",
            "    Uninstalling scipy-1.15.2:\n",
            "      Successfully uninstalled scipy-1.15.2\n",
            "  Attempting uninstall: rsa\n",
            "    Found existing installation: rsa 4.9\n",
            "    Uninstalling rsa-4.9:\n",
            "      Successfully uninstalled rsa-4.9\n",
            "  Attempting uninstall: rlds\n",
            "    Found existing installation: rlds 0.1.8\n",
            "    Uninstalling rlds-0.1.8:\n",
            "      Successfully uninstalled rlds-0.1.8\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "  Attempting uninstall: pyasn1-modules\n",
            "    Found existing installation: pyasn1_modules 0.4.2\n",
            "    Uninstalling pyasn1_modules-0.4.2:\n",
            "      Successfully uninstalled pyasn1_modules-0.4.2\n",
            "  Attempting uninstall: portpicker\n",
            "    Found existing installation: portpicker 1.6.0\n",
            "    Uninstalling portpicker-1.6.0:\n",
            "      Successfully uninstalled portpicker-1.6.0\n",
            "  Attempting uninstall: ml_dtypes\n",
            "    Found existing installation: ml-dtypes 0.2.0\n",
            "    Uninstalling ml-dtypes-0.2.0:\n",
            "      Successfully uninstalled ml-dtypes-0.2.0\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.13.0\n",
            "    Uninstalling h5py-3.13.0:\n",
            "      Successfully uninstalled h5py-3.13.0\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.23.0\n",
            "    Uninstalling gym-0.23.0:\n",
            "      Successfully uninstalled gym-0.23.0\n",
            "  Attempting uninstall: google-pasta\n",
            "    Found existing installation: google-pasta 0.2.0\n",
            "    Uninstalling google-pasta-0.2.0:\n",
            "      Successfully uninstalled google-pasta-0.2.0\n",
            "  Attempting uninstall: dm-tree\n",
            "    Found existing installation: dm-tree 0.1.9\n",
            "    Uninstalling dm-tree-0.1.9:\n",
            "      Successfully uninstalled dm-tree-0.1.9\n",
            "  Attempting uninstall: astunparse\n",
            "    Found existing installation: astunparse 1.6.3\n",
            "    Uninstalling astunparse-1.6.3:\n",
            "      Successfully uninstalled astunparse-1.6.3\n",
            "  Attempting uninstall: tensorflow-probability\n",
            "    Found existing installation: tensorflow-probability 0.19.0\n",
            "    Uninstalling tensorflow-probability-0.19.0:\n",
            "      Successfully uninstalled tensorflow-probability-0.19.0\n",
            "  Attempting uninstall: requests-oauthlib\n",
            "    Found existing installation: requests-oauthlib 2.0.0\n",
            "    Uninstalling requests-oauthlib-2.0.0:\n",
            "      Successfully uninstalled requests-oauthlib-2.0.0\n",
            "  Attempting uninstall: jaxlib\n",
            "    Found existing installation: jaxlib 0.4.38\n",
            "    Uninstalling jaxlib-0.4.38:\n",
            "      Successfully uninstalled jaxlib-0.4.38\n",
            "  Attempting uninstall: google-auth\n",
            "    Found existing installation: google-auth 2.39.0\n",
            "    Uninstalling google-auth-2.39.0:\n",
            "      Successfully uninstalled google-auth-2.39.0\n",
            "  Attempting uninstall: dm-reverb\n",
            "    Found existing installation: dm-reverb 0.11.0\n",
            "    Uninstalling dm-reverb-0.11.0:\n",
            "      Successfully uninstalled dm-reverb-0.11.0\n",
            "  Attempting uninstall: tf-agents\n",
            "    Found existing installation: tf-agents 0.16.0\n",
            "    Uninstalling tf-agents-0.16.0:\n",
            "      Successfully uninstalled tf-agents-0.16.0\n",
            "  Attempting uninstall: jax\n",
            "    Found existing installation: jax 0.4.38\n",
            "    Uninstalling jax-0.4.38:\n",
            "      Successfully uninstalled jax-0.4.38\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.1\n",
            "    Uninstalling google-auth-oauthlib-1.2.1:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.15.2\n",
            "    Uninstalling tensorboard-2.15.2:\n",
            "      Successfully uninstalled tensorboard-2.15.2\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.15.0\n",
            "    Uninstalling tensorflow-2.15.0:\n",
            "      Successfully uninstalled tensorflow-2.15.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "google-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.39.0 which is incompatible.\n",
            "google-colab 1.0.0 requires portpicker==1.5.2, but you have portpicker 1.6.0 which is incompatible.\n",
            "langchain-core 0.3.51 requires typing-extensions>=4.7, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "moviepy 1.0.3 requires decorator<5.0,>=4.0.2, but you have decorator 5.2.1 which is incompatible.\n",
            "tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.12.1 which is incompatible.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.12.1 which is incompatible.\n",
            "albumentations 2.0.5 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.12.1 which is incompatible.\n",
            "pymc 5.21.2 requires numpy>=1.25.0, but you have numpy 1.24.3 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.24.3 which is incompatible.\n",
            "flax 0.10.5 requires jax>=0.5.1, but you have jax 0.4.38 which is incompatible.\n",
            "pydantic-core 2.33.1 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "albucore 0.0.23 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\n",
            "typing-inspection 0.4.0 requires typing-extensions>=4.12.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "altair 5.5.0 requires typing-extensions>=4.10.0; python_version < \"3.14\", but you have typing-extensions 4.5.0 which is incompatible.\n",
            "openai 1.72.0 requires typing-extensions<5,>=4.11, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "nibabel 5.3.2 requires typing-extensions>=4.6; python_version < \"3.13\", but you have typing-extensions 4.5.0 which is incompatible.\n",
            "google-genai 1.10.0 requires typing-extensions<5.0.0,>=4.11.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "pydantic 2.11.3 requires typing-extensions>=4.12.2, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.6 which is incompatible.\n",
            "typeguard 4.4.2 requires typing_extensions>=4.10.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "blosc2 3.3.0 requires numpy>=1.26, but you have numpy 1.24.3 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.24.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires typing-extensions>=4.10.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "sqlalchemy 2.0.40 requires typing-extensions>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.6 which is incompatible.\n",
            "orbax-checkpoint 0.11.12 requires jax>=0.5.0, but you have jax 0.4.38 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-3.0.2 absl-py-2.2.2 astunparse-1.6.3 attrs-25.3.0 cachetools-5.5.2 certifi-2025.1.31 charset-normalizer-3.4.1 cloudpickle-3.1.1 decorator-5.2.1 dm-reverb-0.11.0 dm-tree-0.1.9 flatbuffers-25.2.10 gast-0.4.0 gin-config-0.5.0 google-auth-2.39.0 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.71.0 gym-0.23.0 gym_notices-0.0.8 h5py-3.13.0 idna-3.10 jax-0.4.38 jaxlib-0.4.38 keras-2.12.0 libclang-18.1.1 markdown-3.8 ml_dtypes-0.5.1 numpy-1.24.3 oauthlib-3.2.2 opt-einsum-3.4.0 packaging-24.2 pillow-11.2.1 portpicker-1.6.0 protobuf-4.25.6 psutil-7.0.0 pyasn1-0.6.1 pyasn1-modules-0.4.2 pygame-2.1.3 requests-2.32.3 requests-oauthlib-2.0.0 rlds-0.1.8 rsa-4.9 scipy-1.15.2 setuptools-78.1.0 six-1.17.0 tensorboard-2.12.3 tensorboard-data-server-0.7.2 tensorflow-2.12.1 tensorflow-estimator-2.12.0 tensorflow-io-gcs-filesystem-0.37.1 tensorflow-probability-0.19.0 termcolor-3.0.1 tf-agents-0.16.0 typing-extensions-4.5.0 urllib3-2.4.0 werkzeug-3.1.3 wheel-0.45.1 wrapt-1.14.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "_distutils_hack",
                  "absl",
                  "astunparse",
                  "cachetools",
                  "certifi",
                  "charset_normalizer",
                  "decorator",
                  "flatbuffers",
                  "gast",
                  "gin",
                  "google",
                  "gym",
                  "gym_notices",
                  "h5py",
                  "jax",
                  "jaxlib",
                  "keras",
                  "ml_dtypes",
                  "numpy",
                  "pkg_resources",
                  "portpicker",
                  "psutil",
                  "pyasn1",
                  "pyasn1_modules",
                  "pygame",
                  "requests",
                  "setuptools",
                  "six",
                  "tensorboard",
                  "tensorflow",
                  "tensorflow_probability",
                  "tf_agents",
                  "tree",
                  "wrapt"
                ]
              },
              "id": "fff37d16b1fe475eb6de7f313d082158"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.23.5\n",
            "  Using cached numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Using cached numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.24.3\n",
            "    Uninstalling numpy-1.24.3:\n",
            "      Successfully uninstalled numpy-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jax 0.4.38 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "jaxlib 0.4.38 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "xarray 2025.1.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "bigframes 1.42.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "moviepy 1.0.3 requires decorator<5.0,>=4.0.2, but you have decorator 5.2.1 which is incompatible.\n",
            "chex 0.1.89 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.12.1 which is incompatible.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.12.1 which is incompatible.\n",
            "albumentations 2.0.5 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.12.1 which is incompatible.\n",
            "pymc 5.21.2 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.23.5 which is incompatible.\n",
            "flax 0.10.5 requires jax>=0.5.1, but you have jax 0.4.38 which is incompatible.\n",
            "albucore 0.0.23 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "nibabel 5.3.2 requires typing-extensions>=4.6; python_version < \"3.13\", but you have typing-extensions 4.5.0 which is incompatible.\n",
            "scikit-image 0.25.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.6 which is incompatible.\n",
            "blosc2 3.3.0 requires numpy>=1.26, but you have numpy 1.23.5 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.23.5 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires numpy<3,>=1.24.3, but you have numpy 1.23.5 which is incompatible.\n",
            "orbax-checkpoint 0.11.12 requires jax>=0.5.0, but you have jax 0.4.38 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.23.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "809863fb108145338c424f13ce6a8cfe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gym in /usr/local/lib/python3.11/dist-packages (0.23.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.11/dist-packages (from gym) (1.23.5)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gym) (3.1.1)\n",
            "Requirement already satisfied: gym_notices>=0.0.4 in /usr/local/lib/python3.11/dist-packages (from gym) (0.0.8)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade --force-reinstall tensorflow==2.15.0\n",
        "!pip install --upgrade --force-reinstall tf-agents[reverb]==0.16.0\n",
        "!pip install --upgrade --force-reinstall numpy==1.23.5\n",
        "!pip install gym"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Importation**"
      ],
      "metadata": {
        "id": "7KpzsqKYHF9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tf_agents.environments import suite_gym\n",
        "from tf_agents.environments import tf_py_environment\n",
        "from tf_agents.networks import q_network\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tf_agents.policies import epsilon_greedy_policy\n",
        "from tf_agents.utils import common\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "from tf_agents.agents.dqn.dqn_agent import DqnAgent\n",
        "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
        "from tf_agents.policies import random_tf_policy\n",
        "from tf_agents.drivers import dynamic_step_driver"
      ],
      "metadata": {
        "id": "w_D_mVf95ELp"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercice 1 : PrÃ©paration de l'environnement**\n",
        "---"
      ],
      "metadata": {
        "id": "pECuDhz8HXjY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. CrÃ©ation d'environnement CartPole-v0**"
      ],
      "metadata": {
        "id": "imocmzNtHlSn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = suite_gym.load('CartPole-v0')\n",
        "tf_env = tf_py_environment.TFPyEnvironment(env)"
      ],
      "metadata": {
        "id": "JsGhgVzD_U5u"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Affichage des spÃ©cifications de l'environnement**"
      ],
      "metadata": {
        "id": "RvLgnLQgHxRL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Observation specs:\", tf_env.observation_spec())\n",
        "print(\"Action specs:\", tf_env.action_spec())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dfe34WVtBPSv",
        "outputId": "901d4480-e5e2-402d-d298-2ea628f32ae2"
      },
      "execution_count": 69,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Observation specs: BoundedTensorSpec(shape=(4,), dtype=tf.float32, name='observation', minimum=array([-4.8000002e+00, -3.4028235e+38, -4.1887903e-01, -3.4028235e+38],\n",
            "      dtype=float32), maximum=array([4.8000002e+00, 3.4028235e+38, 4.1887903e-01, 3.4028235e+38],\n",
            "      dtype=float32))\n",
            "Action specs: BoundedTensorSpec(shape=(), dtype=tf.int64, name='action', minimum=array(0), maximum=array(1))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Test d'environnement**"
      ],
      "metadata": {
        "id": "peT7YU1BH5c7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "time_step = tf_env.reset()\n",
        "while not time_step.is_last():\n",
        "    action = np.random.randint(0, env.action_spec().maximum + 1)\n",
        "    time_step = env.step(action)\n",
        "    print(f\"Observation: {time_step.observation}, Reward: {time_step.reward}, Step Type: {time_step.step_type}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgVtuMbNBTYm",
        "outputId": "6178189d-a542-40ec-cef7-46baca8ae6bf"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Observation: [-0.02748408  0.20482047  0.03344937 -0.24554628], Reward: 1.0, Step Type: 1\n",
            "Observation: [-0.02338767  0.3994491   0.02853845 -0.52749366], Reward: 1.0, Step Type: 1\n",
            "Observation: [-0.01539869  0.20393749  0.01798858 -0.22595647], Reward: 1.0, Step Type: 1\n",
            "Observation: [-0.01131994  0.3987978   0.01346945 -0.51291126], Reward: 1.0, Step Type: 1\n",
            "Observation: [-0.00334398  0.59372747  0.00321122 -0.80131936], Reward: 1.0, Step Type: 1\n",
            "Observation: [ 0.00853057  0.39856163 -0.01281517 -0.507628  ], Reward: 1.0, Step Type: 1\n",
            "Observation: [ 0.0165018   0.59386176 -0.02296773 -0.80432177], Reward: 1.0, Step Type: 1\n",
            "Observation: [ 0.02837903  0.39906213 -0.03905416 -0.51895124], Reward: 1.0, Step Type: 1\n",
            "Observation: [ 0.03636028  0.20451114 -0.04943319 -0.23882629], Reward: 1.0, Step Type: 1\n",
            "Observation: [ 0.0404505   0.01012895 -0.05420971  0.03786337], Reward: 1.0, Step Type: 1\n",
            "Observation: [ 0.04065308  0.20598468 -0.05345244 -0.2714185 ], Reward: 1.0, Step Type: 1\n",
            "Observation: [ 0.04477277  0.401827   -0.05888081 -0.58046997], Reward: 1.0, Step Type: 1\n",
            "Observation: [ 0.05280931  0.5977225  -0.07049021 -0.8911049 ], Reward: 1.0, Step Type: 1\n",
            "Observation: [ 0.06476376  0.403624   -0.08831231 -0.6213872 ], Reward: 1.0, Step Type: 1\n",
            "Observation: [ 0.07283624  0.59986097 -0.10074005 -0.94052565], Reward: 1.0, Step Type: 1\n",
            "Observation: [ 0.08483347  0.40623054 -0.11955057 -0.68112004], Reward: 1.0, Step Type: 1\n",
            "Observation: [ 0.09295807  0.21295401 -0.13317297 -0.42833877], Reward: 1.0, Step Type: 1\n",
            "Observation: [ 0.09721715  0.01994468 -0.14173974 -0.18042548], Reward: 1.0, Step Type: 1\n",
            "Observation: [ 0.09761605  0.21678036 -0.14534825 -0.5142502 ], Reward: 1.0, Step Type: 1\n",
            "Observation: [ 0.10195165  0.4136181  -0.15563326 -0.84897554], Reward: 1.0, Step Type: 1\n",
            "Observation: [ 0.11022402  0.6104811  -0.17261277 -1.1862727 ], Reward: 1.0, Step Type: 1\n",
            "Observation: [ 0.12243364  0.41796553 -0.19633822 -0.9522872 ], Reward: 1.0, Step Type: 1\n",
            "Observation: [ 0.13079295  0.61510986 -0.21538396 -1.2996756 ], Reward: 1.0, Step Type: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercice 2 : CrÃ©ation du rÃ©seau et de l'gent**\n",
        "---"
      ],
      "metadata": {
        "id": "XIgRKFV6IBiF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. CrÃ©ation de QNetwork**"
      ],
      "metadata": {
        "id": "nEiAD4y5IS4H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "q_net = q_network.QNetwork(\n",
        "    tf_env.observation_spec(),\n",
        "    tf_env.action_spec(),\n",
        "    fc_layer_params=(100, 50)\n",
        ")\n"
      ],
      "metadata": {
        "id": "DML4frq1Bf40"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. CrÃ©ation d'agent DQN**"
      ],
      "metadata": {
        "id": "klSoYT6lIaEl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
        "train_step_counter = tf.Variable(0)"
      ],
      "metadata": {
        "id": "uJ_LVoyjBhTJ"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tf_agents.agents.dqn import dqn_agent\n",
        "agent = dqn_agent.DqnAgent(\n",
        "    tf_env.time_step_spec(),\n",
        "    tf_env.action_spec(),\n",
        "    q_network=q_net,\n",
        "    optimizer=optimizer,\n",
        "    td_errors_loss_fn=common.element_wise_squared_loss,\n",
        "    train_step_counter=train_step_counter\n",
        ")\n"
      ],
      "metadata": {
        "id": "YK8PVH6KBi2f"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent.initialize()"
      ],
      "metadata": {
        "id": "RXDF6qKQB5lc"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercice 3 : Entrainement et Evaluation**"
      ],
      "metadata": {
        "id": "e6jTTPrEIher"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. CrÃ©ation d'un replay buffer pour stockage des expÃ©riences**"
      ],
      "metadata": {
        "id": "_oGE3gWgIs-b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
        "    data_spec=agent.collect_data_spec,\n",
        "    batch_size=tf_env.batch_size,\n",
        "    max_length=100000\n",
        ")"
      ],
      "metadata": {
        "id": "U4vNLrBIB8XJ"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. ImplÃ©mentation d'une boucle de collecte des donnÃ©es**"
      ],
      "metadata": {
        "id": "rXa7q-w5I3Sy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def collect_step(environment, policy, buffer):\n",
        "    time_step = environment.current_time_step()\n",
        "    action_step = policy.action(time_step)\n",
        "    next_time_step = environment.step(action_step.action)\n",
        "    traj = trajectory.from_transition(time_step, action_step, next_time_step)\n",
        "    buffer.add_batch(traj)"
      ],
      "metadata": {
        "id": "4vrTzbEmB_fS"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. ImplÃ©mentaton de la boucle d'entrainement**"
      ],
      "metadata": {
        "id": "Tm5uJMMzJCQi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_iterations = 10000\n",
        "collect_steps_per_iteration = 1\n",
        "batch_size = 64\n",
        "\n",
        "dataset = replay_buffer.as_dataset(\n",
        "    num_parallel_calls=3,\n",
        "    sample_batch_size=batch_size,\n",
        "    num_steps=2\n",
        ").prefetch(3)\n",
        "\n",
        "iterator = iter(dataset)\n",
        "random_policy = random_tf_policy.RandomTFPolicy(\n",
        "    tf_env.time_step_spec(),\n",
        "    tf_env.action_spec()\n",
        ")\n",
        "for _ in range(num_iterations):\n",
        "    # Collect data\n",
        "    for _ in range(collect_steps_per_iteration):\n",
        "        collect_step(tf_env, agent.collect_policy, replay_buffer)\n",
        "\n",
        "    # Train agent\n",
        "    experience, _ = next(iterator)\n",
        "    train_loss = agent.train(experience).loss\n",
        "\n",
        "    # Log progress\n",
        "    step = agent.train_step_counter.numpy()\n",
        "    if step % 100 == 0:\n",
        "        print(f'step = {step}: loss = {train_loss}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNjRqGURELuv",
        "outputId": "93e41377-55bf-497a-cea6-b6fc7ad45e5b"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step = 5100: loss = 6.723430633544922\n",
            "step = 5200: loss = 10.461040496826172\n",
            "step = 5300: loss = 13.368563652038574\n",
            "step = 5400: loss = 9.804285049438477\n",
            "step = 5500: loss = 28.584152221679688\n",
            "step = 5600: loss = 29.89196014404297\n",
            "step = 5700: loss = 9.770882606506348\n",
            "step = 5800: loss = 10.577302932739258\n",
            "step = 5900: loss = 7.501821517944336\n",
            "step = 6000: loss = 11.675416946411133\n",
            "step = 6100: loss = 41.90787124633789\n",
            "step = 6200: loss = 27.883014678955078\n",
            "step = 6300: loss = 30.549579620361328\n",
            "step = 6400: loss = 21.605113983154297\n",
            "step = 6500: loss = 13.092782974243164\n",
            "step = 6600: loss = 149.81544494628906\n",
            "step = 6700: loss = 5.6103644371032715\n",
            "step = 6800: loss = 5.5682783126831055\n",
            "step = 6900: loss = 5.760518550872803\n",
            "step = 7000: loss = 41.35927200317383\n",
            "step = 7100: loss = 51.664119720458984\n",
            "step = 7200: loss = 50.924476623535156\n",
            "step = 7300: loss = 21.94211196899414\n",
            "step = 7400: loss = 28.024097442626953\n",
            "step = 7500: loss = 70.06224822998047\n",
            "step = 7600: loss = 67.1207504272461\n",
            "step = 7700: loss = 6.555541038513184\n",
            "step = 7800: loss = 4.9199442863464355\n",
            "step = 7900: loss = 123.92815399169922\n",
            "step = 8000: loss = 37.01744079589844\n",
            "step = 8100: loss = 11.84271240234375\n",
            "step = 8200: loss = 42.07109832763672\n",
            "step = 8300: loss = 69.32954406738281\n",
            "step = 8400: loss = 107.84555053710938\n",
            "step = 8500: loss = 68.7349853515625\n",
            "step = 8600: loss = 96.77726745605469\n",
            "step = 8700: loss = 39.72822570800781\n",
            "step = 8800: loss = 105.2166976928711\n",
            "step = 8900: loss = 147.35960388183594\n",
            "step = 9000: loss = 152.08187866210938\n",
            "step = 9100: loss = 105.87528991699219\n",
            "step = 9200: loss = 105.38545989990234\n",
            "step = 9300: loss = 63.59379196166992\n",
            "step = 9400: loss = 20.966821670532227\n",
            "step = 9500: loss = 103.7883529663086\n",
            "step = 9600: loss = 113.93045806884766\n",
            "step = 9700: loss = 52.70406723022461\n",
            "step = 9800: loss = 90.83741760253906\n",
            "step = 9900: loss = 91.48551177978516\n",
            "step = 10000: loss = 155.93215942382812\n",
            "step = 10100: loss = 16.095375061035156\n",
            "step = 10200: loss = 59.17729568481445\n",
            "step = 10300: loss = 215.51971435546875\n",
            "step = 10400: loss = 260.421630859375\n",
            "step = 10500: loss = 91.64014434814453\n",
            "step = 10600: loss = 36.037315368652344\n",
            "step = 10700: loss = 18.913496017456055\n",
            "step = 10800: loss = 119.49353790283203\n",
            "step = 10900: loss = 142.878662109375\n",
            "step = 11000: loss = 102.91880798339844\n",
            "step = 11100: loss = 158.7881317138672\n",
            "step = 11200: loss = 156.0157470703125\n",
            "step = 11300: loss = 92.4173583984375\n",
            "step = 11400: loss = 190.16180419921875\n",
            "step = 11500: loss = 356.95501708984375\n",
            "step = 11600: loss = 133.599609375\n",
            "step = 11700: loss = 20.604259490966797\n",
            "step = 11800: loss = 141.59124755859375\n",
            "step = 11900: loss = 184.8588104248047\n",
            "step = 12000: loss = 117.9672622680664\n",
            "step = 12100: loss = 99.56805419921875\n",
            "step = 12200: loss = 19.31082534790039\n",
            "step = 12300: loss = 338.4369201660156\n",
            "step = 12400: loss = 123.03474426269531\n",
            "step = 12500: loss = 31.142122268676758\n",
            "step = 12600: loss = 76.77500915527344\n",
            "step = 12700: loss = 91.32801055908203\n",
            "step = 12800: loss = 27.30694580078125\n",
            "step = 12900: loss = 212.48876953125\n",
            "step = 13000: loss = 30.48621368408203\n",
            "step = 13100: loss = 27.725177764892578\n",
            "step = 13200: loss = 55.60512924194336\n",
            "step = 13300: loss = 153.83880615234375\n",
            "step = 13400: loss = 56.7615966796875\n",
            "step = 13500: loss = 362.70233154296875\n",
            "step = 13600: loss = 255.953369140625\n",
            "step = 13700: loss = 90.37399291992188\n",
            "step = 13800: loss = 44.3333740234375\n",
            "step = 13900: loss = 313.3224182128906\n",
            "step = 14000: loss = 133.4811553955078\n",
            "step = 14100: loss = 755.0758666992188\n",
            "step = 14200: loss = 75.1488037109375\n",
            "step = 14300: loss = 503.45245361328125\n",
            "step = 14400: loss = 143.7763671875\n",
            "step = 14500: loss = 314.71356201171875\n",
            "step = 14600: loss = 24.259071350097656\n",
            "step = 14700: loss = 22.945444107055664\n",
            "step = 14800: loss = 153.3761749267578\n",
            "step = 14900: loss = 240.26519775390625\n",
            "step = 15000: loss = 53.61558532714844\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Evaluation des performances de l'agent**"
      ],
      "metadata": {
        "id": "mCOWdVT4JSL2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_avg_return(environment, policy, num_episodes=10):\n",
        "    total_return = 0.0\n",
        "    for _ in range(num_episodes):\n",
        "        time_step = environment.reset()\n",
        "        episode_return = 0.0\n",
        "\n",
        "        while not time_step.is_last():\n",
        "            action_step = policy.action(time_step)\n",
        "            time_step = environment.step(action_step.action)\n",
        "            episode_return += time_step.reward\n",
        "        total_return += episode_return\n",
        "\n",
        "    avg_return = total_return / num_episodes\n",
        "    return avg_return.numpy()[0]\n",
        "\n",
        "print('Untrained policy:')\n",
        "print(compute_avg_return(tf_env, agent.policy))\n",
        "\n",
        "\n",
        "print('Trained policy:')\n",
        "print(compute_avg_return(tf_env, agent.policy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuJX2IBZEYAo",
        "outputId": "8b534c73-0e57-463d-a253-f2026b49343b"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Untrained policy:\n",
            "146.5\n",
            "Trained policy:\n",
            "163.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0GlVFsntaSfR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}